{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega Final - Grupo 12\n",
    "***\n",
    "\n",
    "*Introducción a la Minería de Datos - Otoño 2018*\n",
    "\n",
    "Pedro Belmonte,  \n",
    "Jorge Fabry,  \n",
    "Víctor Garrido,  \n",
    "Pablo Ilabaca\n",
    "\n",
    "__[GitHub](https://github.com/VictorPato/mineria-de-datos-entrega-3)__\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "***\n",
    "## Motivación\n",
    "La industria de los videojuegos es una de las más grandes industrias de entretenimiento a nivel mundial. Las mayores publicaciones se enfrentan codo a codo para conseguir el mayor éxito y con esto mayores ventas.\n",
    "\n",
    "En esta industria, como en muchas otras, los críticos juegan un rol vital a la hora de definir la recepción que tendrá un juego. Casi siempre, los críticos reciben copias de juegos antes de que estos sean lanzados al público, por lo que tienen la primera palabra a la hora de publicitar si un juego es de calidad o no.\n",
    "\n",
    "Dado esto, se da origen a un fenómeno en el que los críticos dan muy buena crítica a un juego, tal vez motivados por dinero o por quedar bien con los publicadores para seguir recibiendo acceso exclusivo a los juegos, y luego los usuarios dan un puntaje mucho menor, dejando una sensación de engaño y desencanto. A estos juegos con una gran diferencia de puntaje los llamaremos **fiascos**.\n",
    "\n",
    "<img src=\"media/intro-ejemplos_de_fiascos.PNG\" alt=\"Ejemplos de Fiascos\" title=\"Puntaje de un par de fiascos en Metacritic\" />\n",
    "\n",
    "Interesa entonces utilizar las herramientas que provee este curso para estudiar los distintos patrones que pueden surgir a la hora de puntuar la calidad de un juego. En específico,  lograr crear un _predictor_ para saber, ojalá con bastante seguridad, si un juego será un **fiasco** o no.\n",
    "\n",
    "## Hipótesis\n",
    "Por la información manejada por los miembros del equipo, y lo que se ha observado de los últimos grandes fiascos en la industria de los videojuegos, se intuye que un factor importante a la hora de determinar si un juego será un fiasco o no será el publicador del juego. Esperamos que esta variable tenga alta correlación con los fiascos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set\n",
    "***\n",
    "## Origen\n",
    "Para explorar el fenómeno antes descrito, se utiliza el dataset extraido de https://www.kaggle.com/silver1996/videogames/data.\n",
    "\n",
    "Este se construye de datos de Metacritic.com, el cual incluye 16719 entradas con los datos que se presentan a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "original_data = pd.read_csv('data/Video_Games_Sales_as_at_22_Dec_2016.csv',encoding='latin1')\n",
    "print(\"(Filas x Columnas) = \",original_data.shape)\n",
    "original_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los gráficos presentados a continuación se contruyen con este data set, con la intención de extraer información útil de este.\n",
    "\n",
    "<img src=\"media/datos-publicadores_controversiales.jpg\" alt=\"Publicadores controversiales\" title=\"Publicadores con mayor diferencia de puntajes entre críticos y usuarios\" />\n",
    "<img src=\"media/datos-puntaje_por_genero.png\" alt=\"Puntajes por género\" title=\"Puntaje por género otorgado por los críticos de IGN\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el data set incluye muchas columnas con distintas variables, y también algunas filas que le faltan valores. Para comenzar a usar este data set se debe hacer una limpieza que solo deje datos que sean útiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza\n",
    "El siguiente script en R busca limpiar y ordenar el data set para ser utilizado posteriormente por los clasificadores. Se borran varias columnas que no estarían disponibles cuando sale un juego, como ventas. También se borran columnas que no nos aportarán información al explorar a futuro, como el año de lanzamiento, o el nombre del juego.\n",
    "\n",
    "Se busca tambien limitar la cantidad de valores distintos de varias columnas, para mantener el problema con baja dimensionalidad."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "########### 1 - creacion de la tabla y tipos ################\n",
    "## cambiar esta linea al path del .csv\n",
    "## si se mantiene la estructura de carpetas del repositorio, basta con \n",
    "## dejar el working directory en la ubicacion de este archivo\n",
    "library(readr)\n",
    "videogames <- read_csv(\"../data/Video_Games_Sales_as_at_22_Dec_2016.csv\")\n",
    "\n",
    "# se eliminan las filas que tengan NA (quedan aprox 7000 resultados)\n",
    "filtered_vid = na.omit(videogames)\n",
    "\n",
    "# se arreglan los tipos: user-score a numeric, los otros char a factor\n",
    "filtered_vid$User_Score <- as.numeric(filtered_vid$User_Score)\n",
    "character_vars <- lapply(filtered_vid, class) == \"character\"\n",
    "filtered_vid[, character_vars] <- lapply(filtered_vid[, character_vars], as.factor)\n",
    "\n",
    "# se define la diferencia necesaria para considerar que un juego fue un fiasco\n",
    "# (al comparar user_score con critic_score)\n",
    "dif_for_fail = 2\n",
    "\n",
    "# se crea y pobla la columna que define si un juego es un fiasco o no\n",
    "filtered_vid[\"Is_Fiasco\"] <- NA\n",
    "filtered_vid$Is_Fiasco <- ((filtered_vid$Critic_Score / 10) - filtered_vid$User_Score) > dif_for_fail\n",
    "\n",
    "########## 2 - reduccion de dimensionalidad para Machine Learning ##########\n",
    "## eliminar categorias\n",
    "reduced <- filtered_vid\n",
    "reduced[\"User_Count\"] <- NULL\n",
    "reduced[\"User_Score\"] <- NULL\n",
    "reduced[\"Critic_Count\"] <- NULL\n",
    "reduced[\"Other_Sales\"] <- NULL\n",
    "reduced[\"EU_Sales\"] <- NULL\n",
    "reduced[\"JP_Sales\"] <- NULL\n",
    "reduced[\"NA_Sales\"] <- NULL\n",
    "reduced[\"Year_of_Release\"] <- NULL\n",
    "reduced[\"Name\"] <- NULL\n",
    "reduced[\"Developer\"] <- NULL\n",
    "reduced[\"Developer\"] <- NULL\n",
    "## tomar solo las n consolas mas populares:\n",
    "n = 5\n",
    "popular_console <- reduced\n",
    "popular_console[\"counter\"] <- 1\n",
    "popular_console = aggregate(counter ~ Platform,popular_console,FUN=sum)\n",
    "popular_console = popular_console[order(popular_console$counter,decreasing = T),]\n",
    "reduced <- reduced[reduced$Platform %in% popular_console[1:n,]$Platform,]\n",
    "\n",
    "## tomar solo los n mayores publicadores:\n",
    "n = 10\n",
    "popular_publisher <- reduced\n",
    "popular_publisher[\"counter\"] <- 1\n",
    "popular_publisher = aggregate(counter ~ Publisher,popular_publisher,FUN=sum)\n",
    "popular_publisher = popular_publisher[order(popular_publisher$counter,decreasing = T),]\n",
    "reduced <- reduced[reduced$Publisher %in% popular_publisher[1:n,]$Publisher,]\n",
    "#### Descomentar siguiente linea para exportar el dataset\n",
    "write.csv(reduced, file = \"../data/data_para_clasificadores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras esto, se tienen 8 columnas. La primera un número por cada juego. Las siguientes 6 son parámetros, y la última la clase a clasificiar del juego. La clase corresponde a si el juego es un fiasco o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data_para_clasificadores.csv',encoding='latin1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cabe notar que las clases **no** están balanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Cantidad de Fiascos\")\n",
    "data['Is_Fiasco'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptando el Data Set para clasificadores\n",
    "Los clasificadores no pueden trabajar con Strings directamente. Vemos que Platform, Genre, Publisher y Rating son categorías que utilizan Strings, y hay que aplicar algún tipo de transformación para poder alimentarlas al clasificador.\n",
    "\n",
    "Para esto, se utiliza un LabelBinarizer, que permite covertir las distintas categorías de una columna en columnas independientes. El resultado final es una matriz de dimensiones: 2348 rows x 34 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "## Se aplica LabelBinarizer columna por columna, y finalmente se unen los resultados\n",
    "## En header se van guardando los nombres de cada columna para luego agregarlas al nuevo Data Set\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "lb.fit(data[\"Platform\"])\n",
    "platform = lb.transform(data[\"Platform\"])\n",
    "header = lb.classes_\n",
    "\n",
    "lb.fit(data[\"Genre\"])\n",
    "genre = lb.transform(data[\"Genre\"])\n",
    "header = np.append(header,lb.classes_)\n",
    "\n",
    "lb.fit(data[\"Publisher\"])\n",
    "publisher = lb.transform(data[\"Publisher\"])\n",
    "header = np.append(header,lb.classes_)\n",
    "\n",
    "##sales = np.transpose(np.matrix(data[\"Global_Sales\"].values))\n",
    "##header = np.append(header,\"Global_Sales\")\n",
    "\n",
    "critic_score = np.transpose(np.matrix(data[\"Critic_Score\"].values))\n",
    "header = np.append(header,\"Critic_Score\")\n",
    "\n",
    "lb.fit(data[\"Rating\"])\n",
    "rating = lb.transform(data[\"Rating\"])\n",
    "header = np.append(header,lb.classes_)\n",
    "\n",
    "fiasco = np.transpose(np.matrix(data[\"Is_Fiasco\"].values))\n",
    "header = np.append(header,\"Is_Fiasco\")\n",
    "\n",
    "new_matrix = np.hstack((platform,genre,publisher,critic_score,rating,fiasco))\n",
    "new_data = pd.DataFrame(new_matrix)\n",
    "new_data.columns = header\n",
    "\n",
    "## Se separa los datos de los resultados a predecir.\n",
    "X = new_data[new_data.columns[:-1]]\n",
    "y = new_data[new_data.columns[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para observar la nueva data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encontrando nuestro Predictor\n",
    "***\n",
    "## Experimentos básicos para elegir predictor\n",
    "Como _predictor de fiascos_, se busca tener un clasificador que tenga un porcentaje alto de predicción de fiascos. Mediante varios experimentos, se muestra a continuación como se comparan varios clasificadores ante nuestro data set.\n",
    "\n",
    "Utilizando código del laboratorio 2.2 del curso, se comparan distintos clasificadores mediante el contraste de las métricas promedio obtenidas tras un buen número de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import io\n",
    "import pydotplus\n",
    "import imageio\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import GaussianNB  # naive bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC  # support vector machine classifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clf_with_cross_val(clf, X, y, num_tests=100, k=5):\n",
    "    metrics = {'f1-score': [], 'precision': [], 'recall': [], 'score': []}\n",
    "    \n",
    "    for _ in range(num_tests):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30, stratify=y)\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        scores = cross_val_score(clf, X, y, cv=k, scoring='f1')\n",
    "        \n",
    "        metrics['f1-score'].append(f1_score(y_test,predictions))\n",
    "        metrics['recall'].append(recall_score(y_test,predictions))\n",
    "        metrics['precision'].append(precision_score(y_test,predictions))\n",
    "        metrics['score'].append(scores.mean())\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "def run_many_classifiers(X, y, num_test):\n",
    "    c0 = (\"Base Dummy\", DummyClassifier(strategy='stratified'))\n",
    "    c1 = (\"Decision Tree\", DecisionTreeClassifier(min_samples_split=100))\n",
    "    c2 = (\"Gaussian Naive Bayes\", GaussianNB())\n",
    "    c3 = (\"KNN-3\", KNeighborsClassifier(n_neighbors=3))\n",
    "    c4 = (\"KNN-5\", KNeighborsClassifier(n_neighbors=5))\n",
    "    c5 = (\"Random Forest\",RandomForestClassifier(max_features=\"auto\", max_depth=15, n_estimators=40))\n",
    "\n",
    "\n",
    "    classifiers = [c0, c1, c2, c3, c4, c5]\n",
    "    print(\"Corriendo \"+ str(num_test) + \" tests por clasificador\\n\")\n",
    "\n",
    "    for name, clf in classifiers:\n",
    "        metrics = run_clf_with_cross_val(clf, X, y, num_test)\n",
    "        print(\"----------------\")\n",
    "        print(\"Resultados para clasificador: \",name) \n",
    "        print(\"Precision promedio:\",np.array(metrics['precision']).mean())\n",
    "        print(\"Recall promedio:\",np.array(metrics['recall']).mean())\n",
    "        print(\"F1-score promedio:\",np.array(metrics['f1-score']).mean())\n",
    "        print(\"Cross Validation F1-score promedio:\", np.array(metrics['score']).mean())\n",
    "        \n",
    "run_many_classifiers(X, y, 20)\n",
    "warnings.filterwarnings('once')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que los resultados obtenidos no son considerablemente buenos. Tomando en cuenta el F1-score, que describe en general la eficacia de un clasificador, los puntajes son bien bajos, aunque aún así mejores que el base dummy. \n",
    "\n",
    "De todos los clasificadores explorados, Gaussan Naive Bayes y Random Forest son los que se ven más prometedores a predictor de fiascos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando Subsampling y Oversampling\n",
    "En un intento de encontrar mejores resultados que los anteriores, se aplicarán estas estrategias sobre el dataset, buscando que los clasificadores aprendan mejor teniendo clases balanceadas.\n",
    "Nuevamente nos apoyamos en código trabajado en el laboratorio 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling sobre la clase True\n",
    "idx = np.random.choice(new_data.loc[data.Is_Fiasco == True].index, size=1990)\n",
    "data_oversampled = pd.concat([new_data, new_data.iloc[idx]])\n",
    "\n",
    "print(\"Data oversampled on class 'True'\")\n",
    "print(data_oversampled['Is_Fiasco'].value_counts())\n",
    "print()\n",
    "\n",
    "# subsampling sobre la clase False\n",
    "idx = np.random.choice(new_data.loc[new_data.Is_Fiasco == False].index, size=1990, replace=False)\n",
    "data_subsampled = new_data.drop(new_data.iloc[idx].index)\n",
    "\n",
    "print(\"Data subsampled on class 'False'\")\n",
    "print(data_subsampled['Is_Fiasco'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "# datos \"oversampleados\" \n",
    "X_over = data_oversampled[new_data.columns[:-1]]\n",
    "y_over = data_oversampled[new_data.columns[-1]]\n",
    "\n",
    "# datos \"subsampleados\"\n",
    "X_subs = data_subsampled[new_data.columns[:-1]]\n",
    "y_subs = data_subsampled[new_data.columns[-1]]\n",
    "\n",
    "print(\"----------Prueba Oversampling------------\")\n",
    "run_many_classifiers(X_over, y_over, 20)\n",
    "\n",
    "print(\"\\n\\n----------Prueba Subsampling------------\")\n",
    "run_many_classifiers(X_subs, y_subs, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También, como experimento, se buscó hacer subsampling y oversampling al mismo tiempo para no repetir tantos datos, pero tampoco quedarnos con tan pocos. Esto se muestra a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = np.random.choice(new_data.loc[data.Is_Fiasco == True].index, size=71)\n",
    "data_master = pd.concat([new_data, new_data.iloc[idx]])\n",
    "idx = np.random.choice(new_data.loc[new_data.Is_Fiasco == False].index, size=1669, replace=False)\n",
    "data_master = data_master.drop(new_data.iloc[idx].index)\n",
    "print(\"Data subsampled on class 'False' and oversampled on class 'True'\")\n",
    "print(data_master['Is_Fiasco'].value_counts())\n",
    "X_mast = data_master[new_data.columns[:-1]]\n",
    "y_mast = data_master[new_data.columns[-1]]\n",
    "run_many_classifiers(X_mast, y_mast, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráficos de resultados obtenidos\n",
    "A continuación se grafican los resultados obtenidos para Base Dummy, Decision Tree y Random Forest. Como se han corrido varias veces los clasificadores puede que los gráficos no correspondan perfectamente a los valores, pero sí con la cercanía suficiente para ser precisos.\n",
    "<img src=\"media/clasificadores-datos_crudos.png\" alt=\"\" title=\"\" />\n",
    "<img src=\"media/clasificadores-datos_oversampling.png\" alt=\"a\" title=\"a\" />\n",
    "<img src=\"media/clasificadores-datos_subsampling.png\" alt=\"\" title=\"\" />\n",
    "<img src=\"media/clasificadores-datos_over_y_sub.png\" alt=\"\" title=\"\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión Clasificadores\n",
    "Haciendo un análisis de los resultados obtenidos, podemos considerar que **Random Forest** es clasificador que tiene mejor desempeño en cuanto a resultados, en especial al hacer **oversampling**.\n",
    "\n",
    "Si bien no es siempre certero, tiene un puntaje suficiente de exactitud, lo que consideramos un logro aceptable con respecto a lo que esperabamos obtener.\n",
    "Si necesitaramos crear un predictor efectivo, utilizariamos ese clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficando Decision Trees\n",
    "En un ejercicio para explorar la importancia de las variables, y para observar la lógica de los decision trees, se grafican los árboles de decisión, donde los colores indican afinidad con una clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c12= DecisionTreeClassifier(min_samples_split=100)\n",
    "c13= DecisionTreeClassifier(min_samples_split=100)\n",
    "c14= DecisionTreeClassifier(min_samples_split=100)\n",
    "c15= DecisionTreeClassifier(min_samples_split=100)\n",
    "features=new_data.columns[:-1]\n",
    "train, test= train_test_split(new_data,test_size=.30, stratify=y)\n",
    "\n",
    "        \n",
    "X_train= train[features]\n",
    "y_train=train[\"Is_Fiasco\"]\n",
    "\n",
    "X_test=test[features]\n",
    "y_test=test[\"Is_Fiasco\"]\n",
    "\n",
    "dt12=c12.fit(X_train,y_train)\n",
    "dt13=c13.fit(X_over,y_over)\n",
    "dt14=c14.fit(X_subs,y_subs)\n",
    "dt15=c15.fit(X_mast,y_mast)\n",
    "\n",
    "def show_tree(tree, features, path):\n",
    "    path = \"images/\" + path\n",
    "    f= io.StringIO()\n",
    "    export_graphviz(tree, out_file=f, feature_names=features,filled=True,rounded=True)\n",
    "    pydotplus.graph_from_dot_data(f.getvalue()).write_png(path)\n",
    "    img= imageio.imread(path)\n",
    "    plt.rcParams[\"figure.figsize\"]=(20,20)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Árbol Normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tree(dt12, features, 'arbol_normal.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Árbol Oversampled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tree(dt13, features, 'arbol_oversampled.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Árbol Subsampled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tree(dt14, features, 'arbol_subsampled.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Árbol con Oversampling y Subsampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tree(dt15, features, 'arbol_master.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importancia de Atributos\n",
    "Aplicando Random Forest, se pueden obtener los atributos que más seguido se utilizan para discriminar la clase a clasificar. De esta forma se puede evidenciar cuales son las columnas más importantes para decidir si un juego es un fiasco o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "clf6 = RandomForestClassifier(n_estimators= 1000,max_depth=100, random_state=0)\n",
    "train, test= train_test_split(new_data,test_size=.30, stratify=y)\n",
    "        \n",
    "X_train= train[features]\n",
    "y_train=train[\"Is_Fiasco\"]\n",
    "\n",
    "X_test=test[features]\n",
    "y_test=test[\"Is_Fiasco\"]\n",
    "clf6.fit(X_train, y_train)\n",
    "mi_lista_de_tuplas = []\n",
    "for i in range(33):\n",
    "    tupla = (header[i],clf6.feature_importances_[i])\n",
    "    mi_lista_de_tuplas.append(tupla)\n",
    "mi_lista_de_tuplas.sort(key=operator.itemgetter(1), reverse=True)\n",
    "for i in range(33):\n",
    "    print(mi_lista_de_tuplas[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos con esto que la variable más importante por lejos es Critic_Score, lo cual tiene mucho sentido pues con esta en parte se define la clase Is_Fiasco. Luego, dentro de las más importantes tenemos una plataforma (PC), dos publicadores (Activision y EA) y dos géneros (Action y Sports)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "***\n",
    "Se intentó hacer clustering usando K-means con los atributos “Global_Sales”, “Critic_Score” y “User_Score”, usando el siguiente script de R:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "########### 1 - creacion de la tabla y tipos ################\n",
    "## cambiar esta linea al path del .csv\n",
    "## si se mantiene la estructura de carpetas del repositorio, basta con\n",
    "## dejar el working directory en la ubicacion de este archivo\n",
    "library(readr)\n",
    "videogames <-\n",
    "  read_csv(\"../data/Video_Games_Sales_as_at_22_Dec_2016.csv\")\n",
    "\n",
    "# se eliminan las filas que tengan NA (quedan aprox 7000 resultados)\n",
    "filtered_vid = na.omit(videogames)\n",
    "\n",
    "# se arreglan los tipos: user-score a numeric, los otros char a factor\n",
    "filtered_vid$User_Score <- as.numeric(filtered_vid$User_Score)\n",
    "character_vars <- lapply(filtered_vid, class) == \"character\"\n",
    "filtered_vid[, character_vars] <-\n",
    "  lapply(filtered_vid[, character_vars], as.factor)\n",
    "\n",
    "# se define la diferencia necesaria para considerar que un juego fue un fiasco\n",
    "# (al comparar user_score con critic_score)\n",
    "dif_for_fail = 2\n",
    "\n",
    "#se crea y pobla la columna que define si un juego es un fiasco o no\n",
    "filtered_vid[\"Is_Fiasco\"] <- NA\n",
    "filtered_vid$Is_Fiasco <-\n",
    "  ((filtered_vid$Critic_Score / 10) - filtered_vid$User_Score) > dif_for_fail\n",
    "\n",
    "########## 2 - reduccion de dimensionalidad para Machine Learning ##########\n",
    "## eliminar categorias\n",
    "reduced <- filtered_vid\n",
    "reduced[\"User_Count\"] <- NULL\n",
    "reduced[\"User_Score\"] <- NULL\n",
    "reduced[\"Critic_Count\"] <- NULL\n",
    "reduced[\"Other_Sales\"] <- NULL\n",
    "reduced[\"EU_Sales\"] <- NULL\n",
    "reduced[\"JP_Sales\"] <- NULL\n",
    "reduced[\"NA_Sales\"] <- NULL\n",
    "reduced[\"Year_of_Release\"] <- NULL\n",
    "reduced[\"Name\"] <- NULL\n",
    "reduced[\"Developer\"] <- NULL\n",
    "reduced[\"Developer\"] <- NULL\n",
    "## tomar solo las n consolas mas populares:\n",
    "n = 5\n",
    "popular_console <- reduced\n",
    "popular_console[\"counter\"] <- 1\n",
    "popular_console = aggregate(counter ~ Platform, popular_console, FUN = sum)\n",
    "popular_console = popular_console[order(popular_console$counter, decreasing = T), ]\n",
    "reduced <-\n",
    "  reduced[reduced$Platform %in% popular_console[1:n, ]$Platform, ]\n",
    "\n",
    "## tomar solo los n mayores publicadores:\n",
    "n = 10\n",
    "popular_publisher <- reduced\n",
    "popular_publisher[\"counter\"] <- 1\n",
    "popular_publisher = aggregate(counter ~ Publisher, popular_publisher, FUN =\n",
    "                                sum)\n",
    "popular_publisher = popular_publisher[order(popular_publisher$counter, decreasing = T), ]\n",
    "reduced <-\n",
    "  reduced[reduced$Publisher %in% popular_publisher[1:n, ]$Publisher, ]\n",
    "#### Descomentar siguiente linea para exportar el dataset\n",
    "#write.csv(reduced, file = \"../data/data_para_clasificadores.csv\")\n",
    "\n",
    "\n",
    "\n",
    "################    CLUSTERING     ##############\n",
    "\n",
    "\n",
    "datacluster <-\n",
    "  data.frame(reduced[\"Global_Sales\"], reduced[\"Critic_Score\"])#se hace un vector de 2 variables para hacer un cluster\n",
    "plot(datacluster) #lo miro, el me mira\n",
    "\n",
    "# vemos el codo para ver cual k tomar ---------------\n",
    "set.seed(2)\n",
    "wss <- 0\n",
    "clust = 15 # graficaremos hasta 15 clusters\n",
    "for (i in 1:clust) {\n",
    "  wss[i] <-\n",
    "    sum(kmeans(datacluster, centers = i)$withinss)\n",
    "}\n",
    "plot(1:clust,\n",
    "     wss,\n",
    "     type = \"b\",\n",
    "     xlab = \"Numero de clusters\",\n",
    "     ylab = \"wss\")\n",
    "\n",
    "# hacemos kmeans k=3 ------------------------------------\n",
    "set.seed(2)\n",
    "km.out <- kmeans(datacluster, 3, nstart = 20)\n",
    "# vemos los resultados\n",
    "plot(\n",
    "  datacluster,\n",
    "  col = (km.out$cluster),\n",
    "  main = \"Resultados usando k = 3 (plot con colores)\",\n",
    "  xlab = \"Global_Sales\",\n",
    "  ylab = \"Critic_Scores\",\n",
    "  pch = 20,\n",
    "  cex = 2\n",
    ")\n",
    "\n",
    "library(ggplot2) # instalar si es necesario\n",
    "# install.packages(\"GGally\")\n",
    "library(GGally)\n",
    "#otra forma de visualizar\n",
    "datacluster$cluster <- factor(km.out$cluster)\n",
    "ggpairs(datacluster, aes(colour = cluster), alpha = 0.4)\n",
    "#m?s a?n\n",
    "library(\"cluster\") # instalar si es necesario\n",
    "clusplot(\n",
    "  datacluster[, c(1, 2)],\n",
    "  km.out$cluster,\n",
    "  color = TRUE,\n",
    "  shade = TRUE,\n",
    "  labels = 2,\n",
    "  lines = 0,\n",
    "  main = \"IPCAP (k=3)\"\n",
    ")\n",
    "\n",
    "\n",
    "hc.complete <- hclust(dist(datacluster), method = \"complete\")\n",
    "hc.single <- hclust(dist(datacluster), method = \"single\")\n",
    "hc.average <- hclust(dist(datacluster), method = \"average\")\n",
    "par(mfrow = c(1, 3))\n",
    "plot(\n",
    "  hc.complete,\n",
    "  main = \"Complete\",\n",
    "  xlab = \"Global_Sales\",\n",
    "  ylab = \"Critic_Scores\",\n",
    "  cex = .9\n",
    ")\n",
    "plot(\n",
    "  hc.single,\n",
    "  main = \"Single\",\n",
    "  xlab = \"Global_Sales\",\n",
    "  ylab = \"Critic_Scores\",\n",
    "  cex = .9\n",
    ")\n",
    "plot(\n",
    "  hc.average,\n",
    "  main = \"Average\",\n",
    "  xlab = \"Global_Sales\",\n",
    "  ylab = \"Critic_Scores\",\n",
    "  cex = .9\n",
    ")\n",
    "\n",
    "library(\"dbscan\")\n",
    "db <- dbscan(datacluster[, c(1, 2)], eps = 1, minPts = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se consideran las ventas globales y la puntuación de la crítica. Usando el siguiente gráfico y observando los codos se decidió usar K = 3:\n",
    "<img src=\"media/criticscoreglobalsales1.png\" alt=\"\" title=\"\" />\n",
    "\n",
    "Con K = 3 el resultado es el siguiente:\n",
    "\n",
    "<img src=\"media/criticscoreglobalsales2.png\" alt=\"\" title=\"\" />\n",
    "\n",
    "Luego se consideran las ventas globales y puntuación de usuarios. Usando el siguiente gráfico también se decide usar K = 3\n",
    "\n",
    "<img src=\"media/userscoreglobalsales1.png\" alt=\"\" title=\"\" />\n",
    "\n",
    "Con K = 3 el resultado es el siguiente:\n",
    "\n",
    "<img src=\"media/userscoreglobalsales2.png\" alt=\"\" title=\"\" />\n",
    "\n",
    "Luego se consideran las puntuaciones de usuarios y críticos. Usando el siguiente gráfico también se decide usar K = 3\n",
    "\n",
    "<img src=\"media/usercriticscore1.png\" alt=\"\" title=\"\" />\n",
    "\n",
    "Con K = 3 el resultado es el siguiente:\n",
    "\n",
    "<img src=\"media/usercriticscore2.png\" alt=\"\" title=\"\" />\n",
    "\n",
    "Finalmente se hace un cluster tridimensional:\n",
    "\n",
    "<img src=\"media/cluster3d.png\" alt=\"\" title=\"\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reglas de Asociación\n",
    "***\n",
    "Se aplicaron técnicas de reglas de asociación. Para esto primero se hace un preprocesamiento de los datos, en donde, por ejemplo, se definen las clases respecto a la cantidad de ventas (Muchisimas, Muchas, Bastante, Intermedio, Pocas, Muypocas)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "library(readr)  #cargamos readr para poder leer csv's\n",
    "library(arules)  # cargamos arules\n",
    "videogames <- read_csv(\"../data/Video_Games_Sales_as_at_22_Dec_2016.csv\")\n",
    "auxiliar <- videogames #usamos un auxiliar para realizar cambios sin modificar el original\n",
    "\n",
    "# se eliminan las filas que tengan NA (quedan aprox 7000 resultados)\n",
    "sinna = na.omit(videogames)\n",
    "sinnauxiliar = na.omit(videogames)\n",
    "#se definen los intervalos para calificar los atributos num?ricos y asignarles una etiqueta\n",
    "#En caso de haber un n?mero mucho m?s alto que los dem?s, se considera outlier y se le asigna\n",
    "#la etiqueta \"much?simo\" mientras que el segundo n?mero m?s alto se divide en 5 para crear\n",
    "#los intervalos si es que no es un outlier como el anterior\n",
    "\n",
    "#ventas en Norte Am?rica\n",
    "Muchisimas = 40\n",
    "Muchas = 3.136+3.136+3.136+3.136+3.136\n",
    "Bastante = 3.136+3.136+3.136+3.136\n",
    "Intermedio = 3.136+3.136+3.136\n",
    "Pocas= 3.136+3.136\n",
    "Muypocas = 3.136\n",
    "ventasnulas_o_sin_informacion = 0\n",
    "\n",
    "#ventas en Europa\n",
    "Muchisimas2 = 28.96\n",
    "Muchas2 = 2.552+2.552+2.552+2.552+2.552\n",
    "Bastante2 = 2.552+2.552+2.552+2.552\n",
    "Intermedio2 = 2.552+2.552+2.552\n",
    "Pocas2= 2.552+2.552\n",
    "Muypocas2 = 2.552\n",
    "ventasnulas_o_sin_informacion2 = 0\n",
    "\n",
    "#ventas en Jap?n\n",
    "Muchas3 = 1.3+1.3+1.3+1.3+1.3\n",
    "Bastante3 = 1.3+1.3+1.3+1.3\n",
    "Intermedio3 = 1.3+1.3+1.3\n",
    "Pocas3= 1.3+1.3\n",
    "Muypocas3 = 1.3\n",
    "ventasnulas_o_sin_informacion3 = 0\n",
    "\n",
    "#Otras ventas\n",
    "Muchas4 = 2.114+2.114+2.114+2.114+2.114\n",
    "Bastante4 = 2.114+2.114+2.114+2.114\n",
    "Intermedio4 = 2.114+2.114+2.114\n",
    "Pocas4 = 2.114+2.114\n",
    "Muypocas4 = 2.114\n",
    "ventasnulas_o_sin_informacion3 = 0\n",
    "\n",
    "#Ventas globales\n",
    "Muchas5 = 82.53\n",
    "Bastante5 = 2+2+2+2\n",
    "Intermedio5 = 2+2+2\n",
    "Pocas5 = 2+2\n",
    "Muypocas5 = 2\n",
    "ventasnulas_o_sin_informacion4 = 0\n",
    "\n",
    "#se crea una columna extra para ventas de norte am?rica\n",
    "sinna[\"Ventas NA\"] <- NA\n",
    "\n",
    "# se asignan las etiquetas a las ventas de norte am?rica\n",
    "for (i in 1:6947){\n",
    "  if(sinna[i,6]>Muchisimas){\n",
    "    sinna[i,17]=\"muchisimas ventas en NA\"  }\n",
    "  else if (sinna[i,6]>Bastante){\n",
    "    sinna[i,17]=\"muchas ventas en NA\"  }\n",
    "  else if (sinna[i,6]>Intermedio){\n",
    "    sinna[i,17]=\"Bastantes ventas en NA\"  }\n",
    "  else if (sinna[i,6]>Pocas){\n",
    "    sinna[i,17]=\"ventas en NA intermedias\"  }\n",
    "  else if (sinna[i,6]>Muypocas){\n",
    "    sinna[i,17]=\"pocas ventas en NA\"  }\n",
    "  else if (sinna[i,6]>ventasnulas_o_sin_informacion){\n",
    "    sinna[i,17]=\"muy pocas ventas en NA\"  }\n",
    "  else if (sinna[i,6]==ventasnulas_o_sin_informacion){\n",
    "    sinna[i,17]=\"nulas ventas en NA o sin informacion\"  }\n",
    "}\n",
    "\n",
    "#se crea una columna extra para ventas de Europa\n",
    "sinna[\"Ventas EU\"] <- NA\n",
    "\n",
    "for (i in 1:6947){\n",
    "  if(sinna[i,7]==Muchisimas2){\n",
    "    sinna[i,18]=\"muchisimas Ventas en EU\"  }\n",
    "  else if (sinna[i,7]>Bastante2){\n",
    "    sinna[i,18]=\"muchas Ventas en EU\"  }\n",
    "  else if (sinna[i,7]>Intermedio2){\n",
    "    sinna[i,18]=\"Bastantes Ventas en EU \"  }\n",
    "  else if (sinna[i,7]>Pocas2){\n",
    "    sinna[i,18]=\" Ventas en EU intermedias\"  }\n",
    "  else if (sinna[i,7]>Muypocas2){\n",
    "    sinna[i,18]=\"pocas Ventas en EU\"  }\n",
    "  else if (sinna[i,7]>ventasnulas_o_sin_informacion){\n",
    "    sinna[i,18]=\"muy pocas Ventas en EU\"  }\n",
    "  else if (sinna[i,7]==ventasnulas_o_sin_informacion){\n",
    "    sinna[i,18]=\"Ventas en EU nulas o sin informacion\"  }\n",
    "}\n",
    "\n",
    "#se crea una columna extra para ventas de Japon\n",
    "sinna[\"Ventas JP\"] <- NA\n",
    "\n",
    "for (i in 1:6947){\n",
    "  if (sinna[i,8]>Bastante3){\n",
    "    sinna[i,19]=\"muchas Ventas en JP\"  }\n",
    "  else if (sinna[i,8]>Intermedio3){\n",
    "    sinna[i,19]=\"Bastantes Ventas en JP \"  }\n",
    "  else if (sinna[i,8]>Pocas3){\n",
    "    sinna[i,19]=\"Ventas en JP intermedias\"  }\n",
    "  else if (sinna[i,8]>Muypocas3){\n",
    "    sinna[i,19]=\"pocas Ventas en JP\"  }\n",
    "  else if (sinna[i,8]>ventasnulas_o_sin_informacion){\n",
    "    sinna[i,19]=\"muy pocas Ventas en JP\"  }\n",
    "  else if (sinna[i,8]==ventasnulas_o_sin_informacion){\n",
    "    sinna[i,19]=\"nulas Ventas en JP o sin informacion\"  }\n",
    "}\n",
    "\n",
    "#se crea una columna extra para \"otras\" ventas\n",
    "sinna[\"Ventas otras\"] <- NA\n",
    "\n",
    "for (i in 1:6947){\n",
    "  if (sinna[i,9]>Bastante4){\n",
    "    sinna[i,20]=\"muchas Ventas otras\"  }\n",
    "  else if (sinna[i,9]>Intermedio4){\n",
    "    sinna[i,20]=\"Bastantes Ventas otras \"  }\n",
    "  else if (sinna[i,9]>Pocas4){\n",
    "    sinna[i,20]=\"Ventas otras intermedias\"  }\n",
    "  else if (sinna[i,9]>Muypocas4){\n",
    "    sinna[i,20]=\"pocas Ventas otras\"  }\n",
    "  else if (sinna[i,9]>ventasnulas_o_sin_informacion){\n",
    "    sinna[i,20]=\"muy pocas Ventas otras\"  }\n",
    "  else if (sinna[i,9]==ventasnulas_o_sin_informacion){\n",
    "    sinna[i,20]=\"Ventas otras nulas o sin informacion\"  }\n",
    "}\n",
    "\n",
    "#se crea una columna extra para \"otras\" ventas\n",
    "sinna[\"Ventas globales\"] <- NA\n",
    "\n",
    "for (i in 1:6947){\n",
    "  if (sinna[i,10]>Bastante5){\n",
    "    sinna[i,21]=\"muchas Ventas globales\"  }\n",
    "  else if (sinna[i,10]>Intermedio5){\n",
    "    sinna[i,21]=\"Bastantes Ventas globales\"  }\n",
    "  else if (sinna[i,10]>Pocas5){\n",
    "    sinna[i,21]=\"Ventas globales intermedias\"  }\n",
    "  else if (sinna[i,10]>Muypocas5){\n",
    "    sinna[i,21]=\"pocas Ventas globales\"  }\n",
    "  else if (sinna[i,10]>ventasnulas_o_sin_informacion){\n",
    "    sinna[i,21]=\"muy pocas Ventas globales\"  }\n",
    "  else if (sinna[i,10]==ventasnulas_o_sin_informacion){\n",
    "    sinna[i,21]=\"Ventas globales nulas o sin informacion\"  }\n",
    "}\n",
    "\n",
    "# se crean los intervalos para las etiquetas de los puntajes en las cr?ticas de cr?ticos y usuarios y\n",
    "#el n?mero de cr?ticas de cada uno de estos\n",
    "\n",
    "#Puntajes cr?ticos\n",
    "Muchas6 = 100\n",
    "Bastante6 = 80\n",
    "Intermedio6 = 60\n",
    "Pocas6 = 40\n",
    "Muypocas6 = 20\n",
    "ventasnulas_o_sin_informacion4 = 0\n",
    "\n",
    "#Puntajes usuarios\n",
    "Muchas7 = 10\n",
    "Bastante7 = 8\n",
    "Intermedio7 = 6\n",
    "Pocas7 = 4\n",
    "Muypocas7 = 2\n",
    "ventasnulas_o_sin_informacion7 = 0\n",
    "\n",
    "#N? cr?ticas cr?ticos\n",
    "Muchas8 = 22.6+22.6+22.6+22.6+22.6\n",
    "Bastante8 = 22.6+22.6+22.6+22.6\n",
    "Intermedio8 = 22.6+22.6+22.6\n",
    "Pocas8 = 22.6+22.6\n",
    "Muypocas8 = 22.6\n",
    "ventasnulas_o_sin_informacion8 = 0\n",
    "\n",
    "#N? cr?ticas usuarios\n",
    "Muchas9 = 2133+2133+2133+2133+2133\n",
    "Bastante9 = 2133+2133+2133+2133\n",
    "Intermedio9 = 2133+2133+2133\n",
    "Pocas9 = 2133+2133\n",
    "Muypocas9 = 2133\n",
    "ventasnulas_o_sin_informacion8 = 0\n",
    "\n",
    "#se asignan las etiquetas\n",
    "#se crea una columna extra para puntajes de cr?ticos\n",
    "\n",
    "sinna[\"Puntajes Cr?ticos\"] <- NA\n",
    "\n",
    "for (i in 1:6947){\n",
    "  if (sinna[i,11]>Bastante6){\n",
    "    sinna[i,22]=\"Puntajes Cr?ticos muy alto\"  }\n",
    "  else if (sinna[i,11]>Intermedio6){\n",
    "    sinna[i,22]=\"Puntajes Cr?ticos alto\"  }\n",
    "  else if (sinna[i,11]>Pocas6){\n",
    "    sinna[i,22]=\"Puntajes Cr?ticos intermedio\"  }\n",
    "  else if (sinna[i,11]>Muypocas6){\n",
    "    sinna[i,22]=\"Puntajes Cr?ticos bajo\"  }\n",
    "  else if (sinna[i,11]>ventasnulas_o_sin_informacion){\n",
    "    sinna[i,22]=\"Puntajes Cr?ticos muy bajo\"  }\n",
    "  else if (sinna[i,11]==ventasnulas_o_sin_informacion){\n",
    "    sinna[i,22]=\"Puntajes Cr?ticos nulas o sin informacion\"  }\n",
    "}\n",
    "\n",
    "#se crea una columna extra para cantidad de cr?ticas de cr?ticos\n",
    "sinna[\"n? criticas criticos\"] <- NA\n",
    "\n",
    "for (i in 1:6947){\n",
    "  if (sinna[i,12]>Bastante8){\n",
    "    sinna[i,23]=\"n? criticas criticos muy alto\"  }\n",
    "  else if (sinna[i,12]>Intermedio8){\n",
    "    sinna[i,23]=\"n? criticas criticos alto\"  }\n",
    "  else if (sinna[i,12]>Pocas8){\n",
    "    sinna[i,23]=\"n? criticas criticos intermedio\"  }\n",
    "  else if (sinna[i,12]>Muypocas8){\n",
    "    sinna[i,23]=\"n? criticas criticos bajo\"  }\n",
    "  else if (sinna[i,12]>ventasnulas_o_sin_informacion){\n",
    "    sinna[i,23]=\"n? criticas criticos muy bajo\"  }\n",
    "  else if (sinna[i,12]==ventasnulas_o_sin_informacion){\n",
    "    sinna[i,23]=\"n? criticas criticos nulas o sin informacion\"  }\n",
    "}\n",
    "\n",
    "#se crea una columna extra para puntajes de usuarios\n",
    "sinna[\"Puntajes usuarios\"] <- NA\n",
    "\n",
    "for (i in 1:6947){\n",
    "  if (sinna[i,13]>Bastante7){\n",
    "    sinna[i,24]=\"Puntajes usuarios muy alto\"  }\n",
    "  else if (sinna[i,13]>Intermedio7){\n",
    "    sinna[i,24]=\"Puntajes usuarios alto\"  }\n",
    "  else if (sinna[i,13]>Pocas7){\n",
    "    sinna[i,24]=\"Puntajes usuarios intermedio\"  }\n",
    "  else if (sinna[i,13]>Muypocas7){\n",
    "    sinna[i,24]=\"Puntajes usuarios bajo\"  }\n",
    "  else if (sinna[i,13]>ventasnulas_o_sin_informacion){\n",
    "    sinna[i,24]=\"Puntajes usuarios muy bajo\"  }\n",
    "  else if (sinna[i,13]==ventasnulas_o_sin_informacion){\n",
    "    sinna[i,24]=\"Puntajes usuarios nulas o sin informacion\"  }\n",
    "}\n",
    "\n",
    "#se crea una columna extra para n?mero de cr?ticas de usuarios\n",
    "sinna[\"n? cr?ticas usuarios\"] <- NA\n",
    "\n",
    "for (i in 1:6947){\n",
    "  if (sinna[i,14]>Bastante9){\n",
    "    sinna[i,25]=\"n? cr?ticas usuarios muy alto\"  }\n",
    "  else if (sinna[i,14]>Intermedio9){\n",
    "    sinna[i,25]=\"n? cr?ticas usuarios alto\"  }\n",
    "  else if (sinna[i,14]>Pocas9){\n",
    "    sinna[i,25]=\"n? cr?ticas usuarios intermedio\"  }\n",
    "  else if (sinna[i,14]>Muypocas9){\n",
    "    sinna[i,25]=\"n? cr?ticas usuarios bajo\"  }\n",
    "  else if (sinna[i,14]>ventasnulas_o_sin_informacion){\n",
    "    sinna[i,25]=\"n? cr?ticas usuarios muy bajo\"  }\n",
    "  else if (sinna[i,14]==ventasnulas_o_sin_informacion){\n",
    "    sinna[i,25]=\"n? cr?ticas usuarios nulas o sin informacion\"  }\n",
    "}\n",
    "\n",
    "#habiendo asignado todas las etiquetas, se eliminan las columnas num?ricas que\n",
    "#contaminar?an la regla de asociaci?n\n",
    "sinna[\"NA_Sales\"] <- NULL\n",
    "sinna[\"EU_Sales\"] <- NULL\n",
    "sinna[\"JP_Sales\"] <- NULL\n",
    "sinna[\"Other_Sales\"] <- NULL\n",
    "sinna[\"Global_Sales\"] <- NULL\n",
    "sinna[\"Critic_Score\"] <- NULL\n",
    "sinna[\"Critic_Count\"] <- NULL\n",
    "sinna[\"User_Score\"] <- NULL\n",
    "sinna[\"User_Count\"] <- NULL\n",
    "\n",
    "#se crea un dataset con todos los atributos nuevos con etiquetas\n",
    "write.csv(sinna, file = \"../data/conventas.csv\")\n",
    "\n",
    "#se crea otro dataset pero sin atributos que no aportan a las reglas de asociaci?n\n",
    "#se considera que no aportan pues las reglas encontradas asocian esas las etiquetas de esos atributos\n",
    "#sin aportar informaci?n porque o bien la asociaci?n es obvia (por ejemplo: muchas ventas en las distintas regiones del mundo\n",
    "#implican muchas ventas a nivel global)\n",
    "#el nuevo dataset tiene solo las ventas a nivel global, borrando las a nivel de regiones\n",
    "# tambi?n se elimina el rating por las mismas razones\n",
    "sinna[\"Rating\"] <- NULL\n",
    "sinna[\"Ventas JP\"] <- NULL\n",
    "sinna[\"Ventas NA\"] <- NULL\n",
    "sinna[\"Ventas EU\"] <- NULL\n",
    "sinna[\"Ventas otras\"] <- NULL\n",
    "write.csv(sinna, file = \"../data/soloventasglobales.csv\")\n",
    "\n",
    "#se crea un dataset eliminando el atributo de ventas globales, dejando uno sin ventas\n",
    "sinna[\"Ventas globales\"] <- NULL\n",
    "\n",
    "write.csv(sinna, file = \"../data/sinventas.csv\")\n",
    "\n",
    "#se eliminan las columnas relacionadas con el g?nero, la plataforma y el a?o de lanzamiento del videojuego\n",
    "sinna[\"Genre\"] <- NULL\n",
    "sinna[\"Platform\"] <- NULL\n",
    "sinna[\"Year_of_Release\"] <- NULL\n",
    "\n",
    "write.csv(sinna, file = \"../data/singeneroplataformaano.csv\")\n",
    "\n",
    "# se eliminan el n?mero de cr?ticas\n",
    "sinna[\"n? criticas criticos\"] <- NULL\n",
    "sinna[\"n? cr?ticas usuarios\"] <- NULL\n",
    "write.csv(sinna, file = \"../data/sinnumerodecriticas.csv\")\n",
    "sinna2 <- sinna\n",
    "\n",
    "#Luego, se prueba qu? pasa si se deja solamente el atributo del desarrollador o del publicador\n",
    "sinna[\"Developer\"] <- NULL\n",
    "write.csv(sinna, file = \"../data/sindesarrollador.csv\")\n",
    "\n",
    "sinna2[\"Publisher\"] <- NULL\n",
    "write.csv(sinna, file = \"../data/sinpublicador.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de generar estos archivos .csv se aplican las reglas de asociación:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "library(arules)\n",
    "\n",
    "#luego de importar la librer?a necesaria para el m?todo de las reglas de asociaci?n\n",
    "#se leen los archivos .csv creados como transacciones\n",
    "\n",
    "conventas <- read.transactions(\"../data/conventas.csv\", sep=\",\")\n",
    "soloventasglobales<- read.transactions(\"../data/soloventasglobales.csv\", sep=\",\")\n",
    "sinventas <- read.transactions(\"../data/sinventas.csv\", sep=\",\")\n",
    "singeneroplataformaano <- read.transactions(\"../data/singeneroplataformaano.csv\", sep=\",\")\n",
    "sinnumerodecriticas <- read.transactions(\"../data/sinnumerodecriticas.csv\", sep=\",\")\n",
    "sindesarrollador <- read.transactions(\"../data/sindesarrollador.csv\", sep=\",\")\n",
    "sinpublicador <- read.transactions(\"../data/sinpublicador.csv\", sep=\",\")\n",
    "\n",
    "#se aplica la metodolog?a de las reglas de asociaci?n para cada uno de las transacciones\n",
    "\n",
    "rules <- apriori(conventas, parameter=list(support=0.01, confidence=0.5))\n",
    "rules.sorted <- sort(rules, by=\"lift\")\n",
    "rules.sorted.first10 <- head(rules.sorted, 10)\n",
    "inspect(rules.sorted.first10)\n",
    "\n",
    "rules2 <- apriori(soloventasglobales, parameter=list(support=0.01, confidence=0.5))\n",
    "rules2.sorted <- sort(rules2, by=\"lift\")\n",
    "rules2.sorted.first10 <- head(rules2.sorted, 10)\n",
    "inspect(rules2.sorted.first10)\n",
    "\n",
    "rules3 <- apriori(sinventas, parameter=list(support=0.01, confidence=0.5))\n",
    "rules3.sorted <- sort(rules3, by=\"lift\")\n",
    "rules3.sorted.first10 <- head(rules3.sorted, 10)\n",
    "inspect(rules3.sorted.first10)\n",
    "\n",
    "rules4 <- apriori(singeneroplataformaano, parameter=list(support=0.01, confidence=0.5))\n",
    "rules4.sorted <- sort(rules4, by=\"lift\")\n",
    "rules4.sorted.first10 <- head(rules4.sorted, 10)\n",
    "inspect(rules4.sorted.first10)\n",
    "\n",
    "rules5 <- apriori(sinnumerodecriticas, parameter=list(support=0.01, confidence=0.5))\n",
    "rules5.sorted <- sort(rules5, by=\"lift\")\n",
    "rules5.sorted.first10 <- head(rules5.sorted, 30)\n",
    "inspect(rules5.sorted.first10)\n",
    "\n",
    "rules6 <- apriori(sinpublicador, parameter=list(support=0.01, confidence=0.5))\n",
    "rules6.sorted <- sort(rules6, by=\"lift\")\n",
    "rules6.sorted.first10 <- head(rules6.sorted, 10)\n",
    "inspect(rules6.sorted.first10)\n",
    "\n",
    "rules7 <- apriori(sindesarrollador, parameter=list(support=0.01, confidence=0.5))\n",
    "rules7.sorted <- sort(rules7, by=\"lift\")\n",
    "rules7.sorted.first10 <- head(rules7.sorted, 10)\n",
    "inspect(rules7.sorted.first10)\n",
    "\n",
    "#dandose cuenta de que las etiquetas de los puntajes incurren en un error, dado a que\n",
    "#lass cr?ticas pueden ser muy altas por parte de los cr?ticos y muy altas por parte de los usuarios\n",
    "#pero de todas formas puede haber una diferencia de puntajes de 2 puntos lo que clasificar?a como una decepci?n\n",
    "#Se retoma entonces el atributo Is.fiasco que tiene valor \"true\" si hay una diferencia de puntaje de m?s\n",
    "#de dos entre el promedio de puntajes de cr?ticos y usuarios\n",
    "\n",
    "# Se toma el dataset que cuenta con el atributo \"is.fiasco\"\n",
    "data_is_fiasco <- read_csv(\"../data/data_para_clasificadores.csv\")\n",
    "\n",
    "#se borran los atributos que no aportaron a la asociaci?n anterior\n",
    "data_is_fiasco[\"Genre\"] <- NULL\n",
    "data_is_fiasco[\"Platform\"] <- NULL\n",
    "data_is_fiasco[\"Global_Sales\"] <- NULL\n",
    "data_is_fiasco[\"Rating\"] <- NULL\n",
    "\n",
    "data_is_fiasco[\"Critic_Score\"] <- NULL\n",
    "\n",
    "#se crea el dataset para poder ser leido como transacci?n\n",
    "write.csv(data_is_fiasco, file = \"../data/data_para_reglas_de_asociacion.csv\")\n",
    "\n",
    "#se lee el dataset\n",
    "data_reglas_asociacion <- read.transactions(\"../data/data_para_reglas_de_asociacion.csv\", sep=\",\")\n",
    "\n",
    "#se aplica el m?todo de reglas de asociaci?n al dataset que cuenta con \n",
    "#el atributo is.fiasco\n",
    "rules9 <- apriori(data_reglas_asociacion, parameter=list(support=0.001, confidence=0.2))\n",
    "rules9.sorted <- sort(rules9, by=\"lift\")\n",
    "rules9.sorted.first10 <- head(rules9.sorted, 30)\n",
    "inspect(rules9.sorted.first10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto se obtienen los siguientes resultados:\n",
    "> Usando todos los datos se obtienen resultados que no aportan mucha información, como por ejemplo:\n",
    "- {Muchas ventas Regionales} => {Muchas ventas globales}\n",
    "- {Konami,  muy pocas ventas en EU} => {Konami Digital Entertainment}\n",
    "\n",
    "> Considerando solo las ventas globales y no las regionales suceden cosas parecidas:\n",
    "- {muy pocas Ventas globales,  Ubisoft Montreal} => {Ubisoft}\n",
    "\n",
    "> Sin considerar las ventas tampoco se obtienen resultados muy significativos:\n",
    "- {EA Canada, Puntajes usuarios alto} => {Electronic Arts}\n",
    "\n",
    "> Sin el género, la plataforma ni el año:\n",
    "- {Konami,  n° críticas usuarios muy bajo} => {Konami Digital Entertainment}\n",
    "\n",
    "> Sin el número de críticas se obtienen resultados un poco más interesantes, como por ejemplo:\n",
    "- {Nintendo,  Puntajes Críticos muy alto} => {Puntajes usuarios muy alto}\n",
    "\n",
    "> Lo cual a primera vista podría indicar que los juegos de Nintendo tienden a no ser un fiasco, sin embargo, esto es un error pues ambos puntajes podrían ser muy altos según los criterios definidos y aún así tener una diferencia de 2 puntos.\n",
    "\n",
    "> Al eliminar el desarrollador sucede algo parecido al caso anterior, aunque en el caso de Electronic Arts se observa que puntaje de usuarios alto suele estar relacionado con puntaje de críticos aún más alto:\n",
    "- {Electronic Arts, Puntajes usuarios alto} => {Puntajes Críticos muy alto}\n",
    "- {Nintendo, Puntajes Críticos muy alto} => {Puntajes usuarios muy alto}\n",
    "\n",
    "> Con el desarrollador pero sin publicador no se observan cambios significativos.\n",
    "\n",
    "> Al considerar el atributo Is_Fiasco se obtienen los resultados más interesantes, en los cuales se sugiere que el publicador puede estar muy relacionado con la clasificación del videojuego:\n",
    "- {TRUE} => {Activision}\n",
    "- {TRUE} => {Electronic Arts}\n",
    "- {Namco Bandai Games} => {FALSE}\n",
    "- {THQ} => {FALSE}\n",
    "\n",
    "Esto último ayuda a validar las hipótesis iniciales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusión\n",
    "Si bien, se considera que el problema es bastante complejo, pues existen muchos factores difíciles de medir que influyen en lo que sucede en el lanzamiento de un videojuego, los resultados de los experimentos en general fueron interesantes y, en cierta medida, satisfactorios. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
