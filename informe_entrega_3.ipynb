{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega Final - Grupo 12\n",
    "***\n",
    "\n",
    "*Introducción a la Minería de Datos - Otoño 2018*\n",
    "\n",
    "Pedro Belmonte,\n",
    "Jorge Fabry,\n",
    "Víctor Garrido,\n",
    "Pablo Ilabaca\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USAR LA SIGUIENTE URL PARA VER COMO FUNCIONA EL MARKDOWN. BORRAR ANTES DE ENTREGAR\n",
    "https://medium.com/ibm-data-science-experience/markdown-for-jupyter-notebooks-cheatsheet-386c05aeebed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivación\n",
    "***\n",
    "La industria de los videojuegos es una de las más grandes industrias de entretenimiento a nivel mundial. Las mayores publicaciones se enfrentan codo a codo para conseguir el mayor éxito y con esto mayores ventas.\n",
    "\n",
    "En esta industria, como en muchas otras, los críticos juegan un rol vital a la hora de definir la recepción que tendrá un juego. Casi siempre, los críticos reciben copias de juegos antes de que estos sean lanzados al público, por lo que tienen la primera palabra a la hora de publicitar si un juego es de calidad o no.\n",
    "\n",
    "Dado esto, se da origen a un fenómeno en el que los críticos dan muy buena crítica a un juego, tal vez motivados por dinero o por quedar bien con los publicadores para seguir recibiendo acceso exclusivo a los juegos, y luego los usuarios dan un puntaje mucho menor, dejando una sensación de engaño y desencanto. A estos juegos con una gran diferencia de puntaje los llamaremos **fiascos**.\n",
    "\n",
    "<img src=\"media/intro-ejemplos_de_fiascos.PNG\" alt=\"Ejemplos de Fiascos\" title=\"Puntaje de un par de fiascos en Metacritic\" />\n",
    "\n",
    "Interesa entonces utilizar las herramientas que provee este curso para estudiar los distintos patrones que pueden surgir a la hora de puntuar la calidad de un juego. En específico,  lograr crear un _predictor_ para saber, ojalá con bastante seguridad, si un juego será un **fiasco** o no.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set\n",
    "***\n",
    "## Origen\n",
    "Para explorar el fenómeno antes descrito, se utiliza el dataset extraido de https://www.kaggle.com/silver1996/videogames/data.\n",
    "\n",
    "Este se construye de datos de Metacritic.com, el cual incluye 16719 entradas con los datos que se presentan a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Filas x Columnas) =  (16719, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Super Mario Bros.</td>\n",
       "      <td>NES</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>29.08</td>\n",
       "      <td>3.58</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>40.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>35.52</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wii Sports Resort</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>32.77</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pokemon Red/Pokemon Blue</td>\n",
       "      <td>GB</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.27</td>\n",
       "      <td>8.89</td>\n",
       "      <td>10.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name Platform  Year_of_Release         Genre Publisher  \\\n",
       "0                Wii Sports      Wii           2006.0        Sports  Nintendo   \n",
       "1         Super Mario Bros.      NES           1985.0      Platform  Nintendo   \n",
       "2            Mario Kart Wii      Wii           2008.0        Racing  Nintendo   \n",
       "3         Wii Sports Resort      Wii           2009.0        Sports  Nintendo   \n",
       "4  Pokemon Red/Pokemon Blue       GB           1996.0  Role-Playing  Nintendo   \n",
       "\n",
       "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  Critic_Score  \\\n",
       "0     41.36     28.96      3.77         8.45         82.53          76.0   \n",
       "1     29.08      3.58      6.81         0.77         40.24           NaN   \n",
       "2     15.68     12.76      3.79         3.29         35.52          82.0   \n",
       "3     15.61     10.93      3.28         2.95         32.77          80.0   \n",
       "4     11.27      8.89     10.22         1.00         31.37           NaN   \n",
       "\n",
       "   Critic_Count User_Score  User_Count Developer Rating  \n",
       "0          51.0          8       322.0  Nintendo      E  \n",
       "1           NaN        NaN         NaN       NaN    NaN  \n",
       "2          73.0        8.3       709.0  Nintendo      E  \n",
       "3          73.0          8       192.0  Nintendo      E  \n",
       "4           NaN        NaN         NaN       NaN    NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "original_data = pd.read_csv('data/Video_Games_Sales_as_at_22_Dec_2016.csv',encoding='latin1')\n",
    "print(\"(Filas x Columnas) = \",original_data.shape)\n",
    "original_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los gráficos presentados a continuación se contruyen con este data set, con la intención de extraer información útil de este.\n",
    "\n",
    "<img src=\"media/datos-publicadores_controversiales.jpg\" alt=\"Publicadores controversiales\" title=\"Publicadores con mayor diferencia de puntajes entre críticos y usuarios\" />\n",
    "<img src=\"media/datos-puntaje_por_genero.png\" alt=\"Puntajes por género\" title=\"Puntaje por género otorgado por los críticos de IGN\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el data set incluye muchas columnas con distintas variables, y también algunas filas que le faltan valores. Para comenzar a usar este data set se debe hacer una limpieza que solo deje datos que sean útiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza\n",
    "El siguiente script en R busca limpiar y ordenar el data set para ser utilizado posteriormente por los clasificadores. Se borran varias columnas que no estarían disponibles cuando sale un juego, como ventas. También se borran columnas que no nos aportarán información al explorar a futuro, como el año de lanzamiento, o el nombre del juego.\n",
    "\n",
    "Se busca tambien limitar la cantidad de valores distintos de varias columnas, para mantener el problema con baja dimensionalidad."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "########### 1 - creacion de la tabla y tipos ################\n",
    "## cambiar esta linea al path del .csv\n",
    "## si se mantiene la estructura de carpetas del repositorio, basta con \n",
    "## dejar el working directory en la ubicacion de este archivo\n",
    "library(readr)\n",
    "videogames <- read_csv(\"../data/Video_Games_Sales_as_at_22_Dec_2016.csv\")\n",
    "\n",
    "# se eliminan las filas que tengan NA (quedan aprox 7000 resultados)\n",
    "filtered_vid = na.omit(videogames)\n",
    "\n",
    "# se arreglan los tipos: user-score a numeric, los otros char a factor\n",
    "filtered_vid$User_Score <- as.numeric(filtered_vid$User_Score)\n",
    "character_vars <- lapply(filtered_vid, class) == \"character\"\n",
    "filtered_vid[, character_vars] <- lapply(filtered_vid[, character_vars], as.factor)\n",
    "\n",
    "# se define la diferencia necesaria para considerar que un juego fue un fiasco\n",
    "# (al comparar user_score con critic_score)\n",
    "dif_for_fail = 2\n",
    "\n",
    "# se crea y pobla la columna que define si un juego es un fiasco o no\n",
    "filtered_vid[\"Is_Fiasco\"] <- NA\n",
    "filtered_vid$Is_Fiasco <- ((filtered_vid$Critic_Score / 10) - filtered_vid$User_Score) > dif_for_fail\n",
    "\n",
    "########## 2 - reduccion de dimensionalidad para Machine Learning ##########\n",
    "## eliminar categorias\n",
    "reduced <- filtered_vid\n",
    "reduced[\"User_Count\"] <- NULL\n",
    "reduced[\"User_Score\"] <- NULL\n",
    "reduced[\"Critic_Count\"] <- NULL\n",
    "reduced[\"Other_Sales\"] <- NULL\n",
    "reduced[\"EU_Sales\"] <- NULL\n",
    "reduced[\"JP_Sales\"] <- NULL\n",
    "reduced[\"NA_Sales\"] <- NULL\n",
    "reduced[\"Year_of_Release\"] <- NULL\n",
    "reduced[\"Name\"] <- NULL\n",
    "reduced[\"Developer\"] <- NULL\n",
    "reduced[\"Developer\"] <- NULL\n",
    "## tomar solo las n consolas mas populares:\n",
    "n = 5\n",
    "popular_console <- reduced\n",
    "popular_console[\"counter\"] <- 1\n",
    "popular_console = aggregate(counter ~ Platform,popular_console,FUN=sum)\n",
    "popular_console = popular_console[order(popular_console$counter,decreasing = T),]\n",
    "reduced <- reduced[reduced$Platform %in% popular_console[1:n,]$Platform,]\n",
    "\n",
    "## tomar solo los n mayores publicadores:\n",
    "n = 10\n",
    "popular_publisher <- reduced\n",
    "popular_publisher[\"counter\"] <- 1\n",
    "popular_publisher = aggregate(counter ~ Publisher,popular_publisher,FUN=sum)\n",
    "popular_publisher = popular_publisher[order(popular_publisher$counter,decreasing = T),]\n",
    "reduced <- reduced[reduced$Publisher %in% popular_publisher[1:n,]$Publisher,]\n",
    "#### Descomentar siguiente linea para exportar el dataset\n",
    "write.csv(reduced, file = \"../data/data_para_clasificadores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras esto, se tienen 8 columnas. La primera un número por cada juego. Las siguientes 6 son parámetros, y la última la clase a clasificiar del juego. La clase corresponde a si el juego es un fiasco o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Is_Fiasco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>X360</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Microsoft Game Studios</td>\n",
       "      <td>21.81</td>\n",
       "      <td>61</td>\n",
       "      <td>E</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>PS3</td>\n",
       "      <td>Action</td>\n",
       "      <td>Take-Two Interactive</td>\n",
       "      <td>21.04</td>\n",
       "      <td>97</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>PS2</td>\n",
       "      <td>Action</td>\n",
       "      <td>Take-Two Interactive</td>\n",
       "      <td>20.81</td>\n",
       "      <td>95</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>X360</td>\n",
       "      <td>Action</td>\n",
       "      <td>Take-Two Interactive</td>\n",
       "      <td>16.27</td>\n",
       "      <td>97</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>PS2</td>\n",
       "      <td>Action</td>\n",
       "      <td>Take-Two Interactive</td>\n",
       "      <td>16.15</td>\n",
       "      <td>95</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Platform   Genre               Publisher  Global_Sales  \\\n",
       "0           1     X360    Misc  Microsoft Game Studios         21.81   \n",
       "1           2      PS3  Action    Take-Two Interactive         21.04   \n",
       "2           3      PS2  Action    Take-Two Interactive         20.81   \n",
       "3           4     X360  Action    Take-Two Interactive         16.27   \n",
       "4           5      PS2  Action    Take-Two Interactive         16.15   \n",
       "\n",
       "   Critic_Score Rating  Is_Fiasco  \n",
       "0            61      E      False  \n",
       "1            97      M      False  \n",
       "2            95      M      False  \n",
       "3            97      M      False  \n",
       "4            95      M      False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/data_para_clasificadores.csv',encoding='latin1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cabe notar que las clases **no** están balanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de Fiascos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    2169\n",
       "True      179\n",
       "Name: Is_Fiasco, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Cantidad de Fiascos\")\n",
    "data['Is_Fiasco'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptando el Data Set para clasificadores\n",
    "Los clasificadores no pueden trabajar con Strings directamente. Vemos que Platform, Genre, Publisher y Rating son categorías que utilizan Strings, y hay que aplicar algún tipo de transformación para poder alimentarlas al clasificador.\n",
    "\n",
    "Para esto, se utiliza un LabelBinarizer, que permite covertir las distintas categorías de una columna en columnas independientes. El resultado final es una matriz de dimensiones: 2348 rows x 34 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "## Se aplica LabelBinarizer columna por columna, y finalmente se unen los resultados\n",
    "## En header se van guardando los nombres de cada columna para luego agregarlas al nuevo Data Set\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "lb.fit(data[\"Platform\"])\n",
    "platform = lb.transform(data[\"Platform\"])\n",
    "header = lb.classes_\n",
    "\n",
    "lb.fit(data[\"Genre\"])\n",
    "genre = lb.transform(data[\"Genre\"])\n",
    "header = np.append(header,lb.classes_)\n",
    "\n",
    "lb.fit(data[\"Publisher\"])\n",
    "publisher = lb.transform(data[\"Publisher\"])\n",
    "header = np.append(header,lb.classes_)\n",
    "\n",
    "##sales = np.transpose(np.matrix(data[\"Global_Sales\"].values))\n",
    "##header = np.append(header,\"Global_Sales\")\n",
    "\n",
    "critic_score = np.transpose(np.matrix(data[\"Critic_Score\"].values))\n",
    "header = np.append(header,\"Critic_Score\")\n",
    "\n",
    "lb.fit(data[\"Rating\"])\n",
    "rating = lb.transform(data[\"Rating\"])\n",
    "header = np.append(header,lb.classes_)\n",
    "\n",
    "fiasco = np.transpose(np.matrix(data[\"Is_Fiasco\"].values))\n",
    "header = np.append(header,\"Is_Fiasco\")\n",
    "\n",
    "new_matrix = np.hstack((platform,genre,publisher,critic_score,rating,fiasco))\n",
    "new_data = pd.DataFrame(new_matrix)\n",
    "new_data.columns = header\n",
    "\n",
    "## Se separa los datos de los resultados a predecir.\n",
    "X = new_data[new_data.columns[:-1]]\n",
    "y = new_data[new_data.columns[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para observar la nueva data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC</th>\n",
       "      <th>PS2</th>\n",
       "      <th>PS3</th>\n",
       "      <th>X360</th>\n",
       "      <th>XB</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Fighting</th>\n",
       "      <th>Misc</th>\n",
       "      <th>Platform</th>\n",
       "      <th>...</th>\n",
       "      <th>THQ</th>\n",
       "      <th>Take-Two Interactive</th>\n",
       "      <th>Ubisoft</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>AO</th>\n",
       "      <th>E</th>\n",
       "      <th>E10+</th>\n",
       "      <th>M</th>\n",
       "      <th>T</th>\n",
       "      <th>Is_Fiasco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PC  PS2  PS3  X360  XB  Action  Adventure  Fighting  Misc  Platform  \\\n",
       "0   0    0    0     1   0       0          0         0     1         0   \n",
       "1   0    0    1     0   0       1          0         0     0         0   \n",
       "2   0    1    0     0   0       1          0         0     0         0   \n",
       "3   0    0    0     1   0       1          0         0     0         0   \n",
       "4   0    1    0     0   0       1          0         0     0         0   \n",
       "\n",
       "     ...      THQ  Take-Two Interactive  Ubisoft  Critic_Score  AO  E  E10+  \\\n",
       "0    ...        0                     0        0            61   0  1     0   \n",
       "1    ...        0                     1        0            97   0  0     0   \n",
       "2    ...        0                     1        0            95   0  0     0   \n",
       "3    ...        0                     1        0            97   0  0     0   \n",
       "4    ...        0                     1        0            95   0  0     0   \n",
       "\n",
       "   M  T  Is_Fiasco  \n",
       "0  0  0          0  \n",
       "1  1  0          0  \n",
       "2  1  0          0  \n",
       "3  1  0          0  \n",
       "4  1  0          0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encontrando nuestro Predictor\n",
    "***\n",
    "## Experimentos básicos para elegir predictor\n",
    "Como _predictor de fiascos_, se busca tener un clasificador que tenga un porcentaje alto de predicción de fiascos. Mediante varios experimentos, se muestra a continuación como se comparan varios clasificadores ante nuestro data set.\n",
    "\n",
    "Utilizando código del laboratorio 2.2 del curso, se comparan distintos clasificadores mediante el contraste de las métricas promedio obtenidas tras un buen número de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import io\n",
    "import pydotplus\n",
    "import imageio\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import GaussianNB  # naive bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC  # support vector machine classifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clf_with_cross_val(clf, X, y, num_tests=100, k=5):\n",
    "    metrics = {'f1-score': [], 'precision': [], 'recall': [], 'score': []}\n",
    "    \n",
    "    for _ in range(num_tests):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30, stratify=y)\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        scores = cross_val_score(clf, X, y, cv=k, scoring='f1')\n",
    "        \n",
    "        metrics['f1-score'].append(f1_score(y_test,predictions))\n",
    "        metrics['recall'].append(recall_score(y_test,predictions))\n",
    "        metrics['precision'].append(precision_score(y_test,predictions))\n",
    "        metrics['score'].append(scores.mean())\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corriendo 20 tests por clasificador\n",
      "\n",
      "----------------\n",
      "Resultados para clasificador:  Base Dummy\n",
      "Precision promedio: 0.06761795816177552\n",
      "Recall promedio: 0.06296296296296297\n",
      "F1-score promedio: 0.06479496285153433\n",
      "Cross Validation F1-score promedio: 0.07297826923164415\n",
      "----------------\n",
      "Resultados para clasificador:  Decision Tree\n",
      "Precision promedio: 0.22687409812409812\n",
      "Recall promedio: 0.03888888888888889\n",
      "F1-score promedio: 0.06572637415296352\n",
      "Cross Validation F1-score promedio: 0.04978111319574733\n",
      "----------------\n",
      "Resultados para clasificador:  Gaussian Naive Bayes\n",
      "Precision promedio: 0.09390115327314337\n",
      "Recall promedio: 0.875925925925926\n",
      "F1-score promedio: 0.16942452807140326\n",
      "Cross Validation F1-score promedio: 0.1787406621828928\n",
      "----------------\n",
      "Resultados para clasificador:  KNN-3\n",
      "Precision promedio: 0.2191077859002546\n",
      "Recall promedio: 0.0787037037037037\n",
      "F1-score promedio: 0.11487651617180343\n",
      "Cross Validation F1-score promedio: 0.08917704173518129\n",
      "----------------\n",
      "Resultados para clasificador:  KNN-5\n",
      "Precision promedio: 0.33958513708513705\n",
      "Recall promedio: 0.04444444444444444\n",
      "F1-score promedio: 0.0774408369242696\n",
      "Cross Validation F1-score promedio: 0.04525641025641025\n",
      "----------------\n",
      "Resultados para clasificador:  Random Forest\n",
      "Precision promedio: 0.29381528634724347\n",
      "Recall promedio: 0.12962962962962962\n",
      "F1-score promedio: 0.1786841784246084\n",
      "Cross Validation F1-score promedio: 0.14637971169180503\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "def run_many_classifiers(X, y, num_test):\n",
    "    c0 = (\"Base Dummy\", DummyClassifier(strategy='stratified'))\n",
    "    c1 = (\"Decision Tree\", DecisionTreeClassifier(min_samples_split=100))\n",
    "    c2 = (\"Gaussian Naive Bayes\", GaussianNB())\n",
    "    c3 = (\"KNN-3\", KNeighborsClassifier(n_neighbors=3))\n",
    "    c4 = (\"KNN-5\", KNeighborsClassifier(n_neighbors=5))\n",
    "    c5 = (\"Random Forest\",RandomForestClassifier(max_features=\"auto\", max_depth=15, n_estimators=40))\n",
    "\n",
    "\n",
    "    classifiers = [c0, c1, c2, c3, c4, c5]\n",
    "    print(\"Corriendo \"+ str(num_test) + \" tests por clasificador\\n\")\n",
    "\n",
    "    for name, clf in classifiers:\n",
    "        metrics = run_clf_with_cross_val(clf, X, y, num_test)\n",
    "        print(\"----------------\")\n",
    "        print(\"Resultados para clasificador: \",name) \n",
    "        print(\"Precision promedio:\",np.array(metrics['precision']).mean())\n",
    "        print(\"Recall promedio:\",np.array(metrics['recall']).mean())\n",
    "        print(\"F1-score promedio:\",np.array(metrics['f1-score']).mean())\n",
    "        print(\"Cross Validation F1-score promedio:\", np.array(metrics['score']).mean())\n",
    "        \n",
    "run_many_classifiers(X, y, 20)\n",
    "warnings.filterwarnings('once')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que los resultados obtenidos no son considerablemente buenos. Tomando en cuenta el F1-score, que describe en general la eficacia de un clasificador, los puntajes son bien bajos, aunque aún así mejores que el base dummy. \n",
    "\n",
    "De todos los clasificadores explorados, Gaussan Naive Bayes y Random Forest son los que se ven más prometedores a predictor de fiascos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando Subsampling y Oversampling\n",
    "En un intento de encontrar mejores resultados que los anteriores, se aplicarán estas estrategias sobre el dataset, buscando que los clasificadores aprendan mejor teniendo clases balanceadas.\n",
    "Nuevamente nos apoyamos en código trabajado en el laboratorio 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data oversampled on class 'True'\n",
      "1    2169\n",
      "0    2169\n",
      "Name: Is_Fiasco, dtype: int64\n",
      "\n",
      "Data subsampled on class 'False'\n",
      "1    179\n",
      "0    179\n",
      "Name: Is_Fiasco, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# oversampling sobre la clase True\n",
    "idx = np.random.choice(new_data.loc[data.Is_Fiasco == True].index, size=1990)\n",
    "data_oversampled = pd.concat([new_data, new_data.iloc[idx]])\n",
    "\n",
    "print(\"Data oversampled on class 'True'\")\n",
    "print(data_oversampled['Is_Fiasco'].value_counts())\n",
    "print()\n",
    "\n",
    "# subsampling sobre la clase False\n",
    "idx = np.random.choice(new_data.loc[new_data.Is_Fiasco == False].index, size=1990, replace=False)\n",
    "data_subsampled = new_data.drop(new_data.iloc[idx].index)\n",
    "\n",
    "print(\"Data subsampled on class 'False'\")\n",
    "print(data_subsampled['Is_Fiasco'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Prueba Oversampling------------\n",
      "Corriendo 20 tests por clasificador\n",
      "\n",
      "----------------\n",
      "Resultados para clasificador:  Base Dummy\n",
      "Precision promedio: 0.5017586069688724\n",
      "Recall promedio: 0.5010752688172043\n",
      "F1-score promedio: 0.5013421718969218\n",
      "Cross Validation F1-score promedio: 0.5004540187960347\n",
      "----------------\n",
      "Resultados para clasificador:  Decision Tree\n",
      "Precision promedio: 0.7616348295193339\n",
      "Recall promedio: 0.8327188940092165\n",
      "F1-score promedio: 0.7949481885551726\n",
      "Cross Validation F1-score promedio: 0.8011630123410063\n",
      "----------------\n",
      "Resultados para clasificador:  Gaussian Naive Bayes\n",
      "Precision promedio: 0.5694217686636363\n",
      "Recall promedio: 0.9356374807987711\n",
      "F1-score promedio: 0.707667324688157\n",
      "Cross Validation F1-score promedio: 0.6992534059751769\n",
      "----------------\n",
      "Resultados para clasificador:  KNN-3\n",
      "Precision promedio: 0.829533866587503\n",
      "Recall promedio: 0.9855606758832567\n",
      "F1-score promedio: 0.900791113739742\n",
      "Cross Validation F1-score promedio: 0.9014094865515823\n",
      "----------------\n",
      "Resultados para clasificador:  KNN-5\n",
      "Precision promedio: 0.7943743501667033\n",
      "Recall promedio: 0.9913210445468511\n",
      "F1-score promedio: 0.8819246735691155\n",
      "Cross Validation F1-score promedio: 0.8813814717348164\n",
      "----------------\n",
      "Resultados para clasificador:  Random Forest\n",
      "Precision promedio: 0.9013718271275591\n",
      "Recall promedio: 0.9994623655913978\n",
      "F1-score promedio: 0.9478519834968603\n",
      "Cross Validation F1-score promedio: 0.9301989287769276\n",
      "\n",
      "\n",
      "----------Prueba Subsampling------------\n",
      "Corriendo 20 tests por clasificador\n",
      "\n",
      "----------------\n",
      "Resultados para clasificador:  Base Dummy\n",
      "Precision promedio: 0.5134030836907233\n",
      "Recall promedio: 0.5222222222222221\n",
      "F1-score promedio: 0.51650760814213\n",
      "Cross Validation F1-score promedio: 0.495262304781674\n",
      "----------------\n",
      "Resultados para clasificador:  Decision Tree\n",
      "Precision promedio: 0.7005084282331662\n",
      "Recall promedio: 0.5657407407407408\n",
      "F1-score promedio: 0.6169371414779683\n",
      "Cross Validation F1-score promedio: 0.5868436385417516\n",
      "----------------\n",
      "Resultados para clasificador:  Gaussian Naive Bayes\n",
      "Precision promedio: 0.568052383828828\n",
      "Recall promedio: 0.8287037037037036\n",
      "F1-score promedio: 0.6669103309642094\n",
      "Cross Validation F1-score promedio: 0.6725207304826565\n",
      "----------------\n",
      "Resultados para clasificador:  KNN-3\n",
      "Precision promedio: 0.5935453436678537\n",
      "Recall promedio: 0.6601851851851852\n",
      "F1-score promedio: 0.6238600818116958\n",
      "Cross Validation F1-score promedio: 0.5518424968567157\n",
      "----------------\n",
      "Resultados para clasificador:  KNN-5\n",
      "Precision promedio: 0.585188264595893\n",
      "Recall promedio: 0.6592592592592591\n",
      "F1-score promedio: 0.619244537113854\n",
      "Cross Validation F1-score promedio: 0.5603596403596405\n",
      "----------------\n",
      "Resultados para clasificador:  Random Forest\n",
      "Precision promedio: 0.6497295666369814\n",
      "Recall promedio: 0.6462962962962963\n",
      "F1-score promedio: 0.6469527775177254\n",
      "Cross Validation F1-score promedio: 0.6641775958998595\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "# datos \"oversampleados\" \n",
    "X_over = data_oversampled[new_data.columns[:-1]]\n",
    "y_over = data_oversampled[new_data.columns[-1]]\n",
    "\n",
    "# datos \"subsampleados\"\n",
    "X_subs = data_subsampled[new_data.columns[:-1]]\n",
    "y_subs = data_subsampled[new_data.columns[-1]]\n",
    "\n",
    "print(\"----------Prueba Oversampling------------\")\n",
    "run_many_classifiers(X_over, y_over, 20)\n",
    "\n",
    "print(\"\\n\\n----------Prueba Subsampling------------\")\n",
    "run_many_classifiers(X_subs, y_subs, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También, como experimento, se buscó hacer subsampling y oversampling al mismo tiempo para no repetir tantos datos, pero tampoco quedarnos con tan pocos. Esto se muestra a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data subsampled on class 'False' and oversampled on class 'True'\n",
      "0    500\n",
      "1    250\n",
      "Name: Is_Fiasco, dtype: int64\n",
      "Corriendo 10 tests por clasificador\n",
      "\n",
      "----------------\n",
      "Resultados para clasificador:  Base Dummy\n",
      "Precision promedio: 0.3376113912371463\n",
      "Recall promedio: 0.32\n",
      "F1-score promedio: 0.32780224323183055\n",
      "Cross Validation F1-score promedio: 0.3332789375183186\n",
      "----------------\n",
      "Resultados para clasificador:  Decision Tree\n",
      "Precision promedio: 0.5574783243906294\n",
      "Recall promedio: 0.41466666666666663\n",
      "F1-score promedio: 0.451921678038888\n",
      "Cross Validation F1-score promedio: 0.4534841012996352\n",
      "----------------\n",
      "Resultados para clasificador:  Gaussian Naive Bayes\n",
      "Precision promedio: 0.3889042186659567\n",
      "Recall promedio: 0.9226666666666666\n",
      "F1-score promedio: 0.5466160039554434\n",
      "Cross Validation F1-score promedio: 0.544025926856536\n",
      "----------------\n",
      "Resultados para clasificador:  KNN-3\n",
      "Precision promedio: 0.5289647732713185\n",
      "Recall promedio: 0.5066666666666666\n",
      "F1-score promedio: 0.5173844374790344\n",
      "Cross Validation F1-score promedio: 0.5236522047430208\n",
      "----------------\n",
      "Resultados para clasificador:  KNN-5\n",
      "Precision promedio: 0.5015246562155911\n",
      "Recall promedio: 0.45466666666666666\n",
      "F1-score promedio: 0.47597460380544304\n",
      "Cross Validation F1-score promedio: 0.4595696554199309\n",
      "----------------\n",
      "Resultados para clasificador:  Random Forest\n",
      "Precision promedio: 0.6572290245244642\n",
      "Recall promedio: 0.6506666666666666\n",
      "F1-score promedio: 0.6524549193366155\n",
      "Cross Validation F1-score promedio: 0.6171775260297753\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.choice(new_data.loc[data.Is_Fiasco == True].index, size=71)\n",
    "data_master = pd.concat([new_data, new_data.iloc[idx]])\n",
    "idx = np.random.choice(new_data.loc[new_data.Is_Fiasco == False].index, size=1669, replace=False)\n",
    "data_master = data_master.drop(new_data.iloc[idx].index)\n",
    "print(\"Data subsampled on class 'False' and oversampled on class 'True'\")\n",
    "print(data_master['Is_Fiasco'].value_counts())\n",
    "X_mast = data_master[new_data.columns[:-1]]\n",
    "y_mast = data_master[new_data.columns[-1]]\n",
    "run_many_classifiers(X_mast, y_mast, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráficos de resultados obtenidos\n",
    "A continuación se grafican los resultados obtenidos para Base Dummy, Decision Tree y Random Forest. Como se han corrido varias veces los clasificadores puede que los gráficos no correspondan perfectamente a los valores, pero sí con la cercanía suficiente para ser precisos.\n",
    "<img src=\"media/clasificadores-datos_crudos.png\" alt=\"\" title=\"\" />\n",
    "<img src=\"media/clasificadores-datos_oversampling.png\" alt=\"a\" title=\"a\" />\n",
    "<img src=\"media/clasificadores-datos_subsampling.png\" alt=\"\" title=\"\" />\n",
    "<img src=\"media/clasificadores-datos_over_y_sub.png\" alt=\"\" title=\"\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión Clasificadores\n",
    "Haciendo un análisis de los resultados obtenidos, podemos considerar que **Random Forest** es clasificador que tiene mejor desempeño en cuanto a resultados, en especial al hacer **oversampling**.\n",
    "\n",
    "Si bien no es siempre certero, tiene un puntaje suficiente de exactitud, lo que consideramos un logro aceptable con respecto a lo que esperabamos obtener.\n",
    "Si necesitaramos crear un predictor efectivo, utilizariamos ese clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficando Decision Trees\n",
    "En un ejercicio para explorar la importancia de las variables, y para observar la lógica de los decision trees, se grafican los árboles de decisión, donde los colores indican afinidad con una clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "c12= DecisionTreeClassifier(min_samples_split=100)\n",
    "c13= DecisionTreeClassifier(min_samples_split=100)\n",
    "c14= DecisionTreeClassifier(min_samples_split=100)\n",
    "c15= DecisionTreeClassifier(min_samples_split=100)\n",
    "features=new_data.columns[:-1]\n",
    "train, test= train_test_split(new_data,test_size=.30, stratify=y)\n",
    "\n",
    "        \n",
    "X_train= train[features]\n",
    "y_train=train[\"Is_Fiasco\"]\n",
    "\n",
    "X_test=test[features]\n",
    "y_test=test[\"Is_Fiasco\"]\n",
    "\n",
    "dt12=c12.fit(X_train,y_train)\n",
    "dt13=c13.fit(X_over,y_over)\n",
    "dt14=c14.fit(X_subs,y_subs)\n",
    "dt15=c15.fit(X_mast,y_mast)\n",
    "\n",
    "def show_tree(tree, features, path):\n",
    "    path = \"images/\" + path\n",
    "    f= io.StringIO()\n",
    "    export_graphviz(tree, out_file=f, feature_names=features,filled=True,rounded=True)\n",
    "    pydotplus.graph_from_dot_data(f.getvalue()).write_png(path)\n",
    "    img= imageio.imread(path)\n",
    "    plt.rcParams[\"figure.figsize\"]=(20,20)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "#show_tree(dt12, features, 'arbol_normal.png')\n",
    "#show_tree(dt13, features, 'arbol_oversampled.png')\n",
    "#show_tree(dt14, features, 'arbol_subsampled.png')\n",
    "#show_tree(dt15, features, 'arbol_master.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Árbol Normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-a9582bc00ded>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mshow_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'arbol_normal.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-a8ae39b952ef>\u001b[0m in \u001b[0;36mshow_tree\u001b[1;34m(tree, features, path)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mexport_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrounded\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mpydotplus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"figure.figsize\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(path, f, prog)\u001b[0m\n\u001b[0;32m   1808\u001b[0m                 \u001b[1;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1810\u001b[1;33m                 \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1811\u001b[0m             )\n\u001b[0;32m   1812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, path, prog, format)\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m                 \u001b[0mfobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1919\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1958\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m                 raise InvocationException(\n\u001b[1;32m-> 1960\u001b[1;33m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[0;32m   1961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1962\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprog\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "show_tree(dt12, features, 'arbol_normal.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Árbol Oversampled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tree(dt13, features, 'arbol_oversampled.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Árbol Subsampled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tree(dt14, features, 'arbol_subsampled.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Árbol con Oversampling y Subsampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tree(dt15, features, 'arbol_master.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "Se aplica Random Forest para obtener los atributos que tienen mayor importancia en los árboles de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf6 = RandomForestClassifier(n_estimators= 1000,max_depth=100, random_state=0)\n",
    "train, test= train_test_split(new_data,test_size=.30, stratify=y)\n",
    "\n",
    "        \n",
    "X_train= train[features]\n",
    "y_train=train[\"Is_Fiasco\"]\n",
    "\n",
    "X_test=test[features]\n",
    "y_test=test[\"Is_Fiasco\"]\n",
    "clf6.fit(X_train, y_train)\n",
    "import operator\n",
    "mi_lista_de_tuplas = []\n",
    "for i in range(33):\n",
    "    tupla = (header[i],clf6.feature_importances_[i])\n",
    "    mi_lista_de_tuplas.append(tupla)\n",
    "mi_lista_de_tuplas.sort(key=operator.itemgetter(1), reverse=True)\n",
    "for i in range(33):\n",
    "    print(mi_lista_de_tuplas[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
